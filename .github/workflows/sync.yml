name: Sync Garmin Data to BigQuery

on:
  # Run daily at 9 PM UTC
  schedule:
    - cron: '0 21 * * *'
  
  # Allow manual trigger
  workflow_dispatch:

jobs:
  sync:
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Cache GarminDB data
        uses: actions/cache@v4
        with:
          path: |
            ~/.GarminDb
            ~/.garth
          # Use date-based key to cache data for the day, allowing updates within the same day
          key: garmindb-${{ runner.os }}-${{ hashFiles('**/requirements.txt') }}-${{ github.run_number }}
          restore-keys: |
            garmindb-${{ runner.os }}-${{ hashFiles('**/requirements.txt') }}-
            garmindb-${{ runner.os }}-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Configure Garmin credentials
        run: |
          mkdir -p ~/.GarminDb
          cat > ~/.GarminDb/GarminConnectConfig.json << EOF
          {
            "credentials": {
              "user": "${{ secrets.GARMIN_USER }}",
              "password": "${{ secrets.GARMIN_PASSWORD }}"
            },
            "data": {
              "download_days": 3,
              "download_latest_activities": 10,
              "download_all_activities": 100
            }
          }
          EOF
          echo "Config file created at ~/.GarminDb/GarminConnectConfig.json"
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - name: Import Garmin data
        id: import_data
        continue-on-error: true
        run: |
          # Download, import and analyze latest Garmin data
          # Using wrapper to prevent TypeError when stats is None
          # The wrapper also ensures config has proper defaults
          echo "Starting Garmin data import..."
          
          if python garmindb_wrapper.py --download --import --analyze --latest; then
            echo "import_success=true" >> $GITHUB_OUTPUT
            echo "✅ Garmin data import completed successfully"
          else
            echo "import_success=false" >> $GITHUB_OUTPUT
            echo "⚠️ Garmin data import failed or no new data available"
            echo "This may be expected on first run or when there's no new data"
          fi
      
      - name: Sync to BigQuery
        # Only run if import was successful and database exists
        if: steps.import_data.outputs.import_success == 'true'
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          DATASET_ID: garmin_data
        run: |
          echo "Syncing data to BigQuery..."
          if python sync_bq.py; then
            echo "✅ BigQuery sync completed successfully"
          else
            echo "❌ BigQuery sync failed"
            exit 1
          fi
      
      - name: Skip BigQuery sync
        # Inform user if sync was skipped
        if: steps.import_data.outputs.import_success != 'true'
        run: |
          echo "⚠️ Skipping BigQuery sync because Garmin data import was not successful"
          echo "This is expected on the first run or when there's no new data to import"
          echo "The workflow will complete successfully, and sync will occur on the next run with data"
